#!/usr/bin/env python3
"""
DeepDive Analyst - AIæŠ€æœ¯ä¸“å®¶è°ƒç ”ä¸åˆ†ææ™ºèƒ½ä½“å›¢é˜Ÿ
ä¸»ç¨‹åºå…¥å£æ–‡ä»¶

è¿™æ˜¯ä¸€ä¸ªåŸºäºå¤šæ™ºèƒ½ä½“åä½œçš„ç³»ç»Ÿï¼Œèƒ½å¤Ÿé’ˆå¯¹ç”¨æˆ·æå‡ºçš„å¤æ‚ITæŠ€æœ¯é—®é¢˜ï¼Œ
è¿›è¡Œæ·±å…¥çš„ä¿¡æ¯æ£€ç´¢ã€åˆ†æã€æ•´åˆï¼Œå¹¶ç”Ÿæˆç»“æ„åŒ–ã€é«˜è´¨é‡çš„è°ƒç ”æŠ¥å‘Šã€‚
"""

import typer
from rich.console import Console
from rich.panel import Panel
from rich.text import Text

# åˆå§‹åŒ–æ§åˆ¶å°å’ŒTyperåº”ç”¨
console = Console()
app = typer.Typer(
    name="DeepDive Analyst",
    help="AIæŠ€æœ¯ä¸“å®¶è°ƒç ”ä¸åˆ†ææ™ºèƒ½ä½“å›¢é˜Ÿ",
    add_completion=False
)


@app.command()
def research(
    query: str = typer.Option(..., "--query", "-q", help="ç ”ç©¶é—®é¢˜æˆ–æŸ¥è¯¢"),
    output: str = typer.Option("report.md", "--output", "-o", help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„"),
    max_iterations: int = typer.Option(3, "--max-iterations", "-i", help="æœ€å¤§ç ”ç©¶è¿­ä»£æ¬¡æ•°"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—"),
    template: str = typer.Option("auto", "--template", "-t", help="æŒ‡å®šæŠ¥å‘Šæ¨¡æ¿ç±»å‹ (comparison/deep_dive/survey/tutorial/auto)")
):
    """
    æ‰§è¡Œæ·±åº¦æŠ€æœ¯è°ƒç ”åˆ†æ
    
    Args:
        query: ç”¨æˆ·æå‡ºçš„æŠ€æœ¯é—®é¢˜
        output: è¾“å‡ºæŠ¥å‘Šçš„æ–‡ä»¶è·¯å¾„
        max_iterations: æœ€å¤§ç ”ç©¶è¿­ä»£æ¬¡æ•°
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
        template: æŠ¥å‘Šæ¨¡æ¿ç±»å‹
    """
    # é…ç½®æ—¥å¿—çº§åˆ«
    if verbose:
        import logging
        logging.basicConfig(level=logging.INFO)
    
    console.print(Panel.fit(
        Text("DeepDive Analyst", style="bold blue"),
        title="æ¬¢è¿ä½¿ç”¨",
        border_style="blue"
    ))
    
    # æ˜¾ç¤ºå‚æ•°ä¿¡æ¯
    console.print(f"[green]âœ“[/green] æ”¶åˆ°æŸ¥è¯¢: {query}")
    console.print(f"[green]âœ“[/green] è¾“å‡ºæ–‡ä»¶: {output}")
    console.print(f"[green]âœ“[/green] æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
    console.print(f"[green]âœ“[/green] æŠ¥å‘Šæ¨¡æ¿: {template}")
    console.print(f"[green]âœ“[/green] è¯¦ç»†æ—¥å¿—: {'å¼€å¯' if verbose else 'å…³é—­'}")
    
    try:
        # å¯¼å…¥å·¥ä½œæµ
        from src.workflows.langgraph_workflow import LangGraphWorkflow
        
        # åˆ›å»ºå¹¶æ‰§è¡Œå·¥ä½œæµ
        console.print("[blue]ğŸš€[/blue] å¼€å§‹æ‰§è¡ŒLangGraphè°ƒç ”å·¥ä½œæµ...")
        workflow = LangGraphWorkflow()
        
        # å¦‚æœæŒ‡å®šäº†æ¨¡æ¿ç±»å‹ï¼Œè¦†ç›–è‡ªåŠ¨åˆ†ç±»
        if template != "auto":
            console.print(f"[yellow]ğŸ“[/yellow] ä½¿ç”¨æŒ‡å®šæ¨¡æ¿: {template}")
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ¨¡æ¿è¦†ç›–é€»è¾‘
        
        results = workflow.execute(query, max_iterations=max_iterations)
        
        if results['success']:
            # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
            with open(output, 'w', encoding='utf-8') as f:
                f.write(results['final_report'])
            
            console.print(f"[green]âœ…[/green] è°ƒç ”å®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output}")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            console.print(f"[blue]ğŸ“Š[/blue] ç ”ç©¶è¿­ä»£æ¬¡æ•°: {results.get('research_iterations', 0)}")
            console.print(f"[blue]ğŸ“Š[/blue] æŸ¥è¯¢æ„å›¾: {results.get('intent', 'æœªçŸ¥')}")
            
            # æ˜¾ç¤ºLangSmithè¿½è¸ªä¿¡æ¯
            if results.get('langsmith_enabled', False):
                langsmith_info = results.get('langsmith_info', {})
                console.print(f"[magenta]ğŸ”[/magenta] LangSmithè¿½è¸ª: å·²å¯ç”¨")
                console.print(f"[magenta]ğŸ“ˆ[/magenta] é¡¹ç›®: {langsmith_info.get('project', 'deepdive-analyst')}")
                console.print(f"[magenta]ğŸŒ[/magenta] æ§åˆ¶å°: {langsmith_info.get('trace_url', 'https://smith.langchain.com/')}")
                console.print(f"[magenta]ğŸ’¡[/magenta] {langsmith_info.get('message', 'è¯·è®¿é—®LangSmithæ§åˆ¶å°æŸ¥çœ‹è¯¦ç»†è½¨è¿¹')}")
            
            # æ˜¾ç¤ºå·¥ä½œæµæ‘˜è¦
            if verbose:
                summary = workflow.get_workflow_summary(results)
                console.print(Panel(
                    summary,
                    title="å·¥ä½œæµæ‰§è¡Œæ‘˜è¦",
                    border_style="green"
                ))
        else:
            console.print(f"[red]âŒ[/red] è°ƒç ”å¤±è´¥: {results.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
    except ImportError as e:
        console.print(f"[red]âŒ[/red] å¯¼å…¥é”™è¯¯: {str(e)}")
        console.print("[yellow]ğŸ’¡[/yellow] è¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–: pip install -r requirements.txt")
    except Exception as e:
        console.print(f"[red]âŒ[/red] æ‰§è¡Œé”™è¯¯: {str(e)}")
        if verbose:
            import traceback
            console.print(f"[red]è¯¦ç»†é”™è¯¯ä¿¡æ¯:[/red]\n{traceback.format_exc()}")


@app.command()
def version():
    """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
    console.print("[bold blue]DeepDive Analyst v1.0.0[/bold blue]")
    console.print("AIæŠ€æœ¯ä¸“å®¶è°ƒç ”ä¸åˆ†ææ™ºèƒ½ä½“å›¢é˜Ÿ")
    console.print("\n[bold]æŠ€æœ¯æ ˆ:[/bold]")
    console.print("- CrewAI: å¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶")
    console.print("- LangGraph: å·¥ä½œæµç¼–æ’")
    console.print("- Tavily: ç½‘ç»œæœç´¢API")
    console.print("- OpenAI: å¤§è¯­è¨€æ¨¡å‹")


@app.command()
def config():
    """æ˜¾ç¤ºå½“å‰é…ç½®ä¿¡æ¯"""
    try:
        from src.configs.config import Config
        
        console.print("[bold blue]DeepDive Analyst é…ç½®ä¿¡æ¯[/bold blue]")
        
        # LLMé…ç½®ä¿¡æ¯
        llm_config = Config.get_llm_config()
        console.print(f"[green]âœ“[/green] LLMæä¾›å•†: {llm_config['provider']}")
        console.print(f"[green]âœ“[/green] LLMæ¨¡å‹: {llm_config['model']}")
        console.print(f"[green]âœ“[/green] æ¨¡å‹æ¸©åº¦: {llm_config['temperature']}")
        console.print(f"[green]âœ“[/green] æœ€å¤§Tokenæ•°: {llm_config['max_tokens']}")
        console.print(f"[green]âœ“[/green] è¶…æ—¶æ—¶é—´: {llm_config['timeout']}ç§’")
        console.print(f"[green]âœ“[/green] æœ€å¤§é‡è¯•æ¬¡æ•°: {llm_config['max_retries']}")
        
        # å…¶ä»–é…ç½®
        console.print(f"[green]âœ“[/green] æœ€å¤§æœç´¢ç»“æœ: {Config.MAX_SEARCH_RESULTS}")
        console.print(f"[green]âœ“[/green] æœç´¢è¶…æ—¶: {Config.SEARCH_TIMEOUT}ç§’")
        console.print(f"[green]âœ“[/green] é»˜è®¤è¾“å‡ºæ–‡ä»¶: {Config.DEFAULT_OUTPUT_FILE}")
        
        # æ£€æŸ¥APIå¯†é’¥çŠ¶æ€
        console.print("\n[bold]APIå¯†é’¥çŠ¶æ€:[/bold]")
        openai_status = "âœ… å·²é…ç½®" if Config.OPENAI_API_KEY else "âŒ æœªé…ç½®"
        gemini_status = "âœ… å·²é…ç½®" if Config.GEMINI_API_KEY else "âŒ æœªé…ç½®"
        qwen_status = "âœ… å·²é…ç½®" if Config.QWEN_API_KEY else "âŒ æœªé…ç½®"
        anthropic_status = "âœ… å·²é…ç½®" if Config.ANTHROPIC_API_KEY else "âŒ æœªé…ç½®"
        tavily_status = "âœ… å·²é…ç½®" if Config.TAVILY_API_KEY else "âŒ æœªé…ç½®"
        langsmith_status = "âœ… å·²é…ç½®" if Config.LANGCHAIN_API_KEY else "âŒ æœªé…ç½®"
        
        console.print(f"[green]OpenAI API:[/green] {openai_status}")
        console.print(f"[green]Gemini API:[/green] {gemini_status}")
        console.print(f"[green]Qwen API:[/green] {qwen_status}")
        console.print(f"[green]Anthropic API:[/green] {anthropic_status}")
        console.print(f"[green]Tavily API:[/green] {tavily_status}")
        console.print(f"[green]LangSmith API:[/green] {langsmith_status}")
        
        # LLMé…ç½®éªŒè¯
        console.print("\n[bold]LLMé…ç½®éªŒè¯:[/bold]")
        if Config.validate_llm_config():
            console.print("[green]âœ… LLMé…ç½®æœ‰æ•ˆ[/green]")
        else:
            console.print("[red]âŒ LLMé…ç½®æ— æ•ˆ[/red]")
            console.print("[yellow]ğŸ’¡ è¯·æ£€æŸ¥LLM_PROVIDERã€LLM_MODELå’Œå¯¹åº”çš„APIå¯†é’¥é…ç½®[/yellow]")
        
    except ImportError as e:
        console.print(f"[red]âŒ[/red] é…ç½®åŠ è½½å¤±è´¥: {str(e)}")


@app.command()
def examples():
    """æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹"""
    console.print("[bold blue]DeepDive Analyst ä½¿ç”¨ç¤ºä¾‹[/bold blue]")
    
    console.print("\n[bold]1. å¯¹æ¯”åˆ†æç¤ºä¾‹:[/bold]")
    console.print("[green]python main.py research --query \"å¯¹æ¯”Reactå’ŒVueçš„ä¼˜ç¼ºç‚¹\" --template comparison[/green]")
    
    console.print("\n[bold]2. æ·±åº¦è§£æç¤ºä¾‹:[/bold]")
    console.print("[green]python main.py research --query \"æ·±å…¥è§£é‡ŠDockerå®¹å™¨æŠ€æœ¯\" --template deep_dive[/green]")
    
    console.print("\n[bold]3. æŠ€æœ¯å·¡è§ˆç¤ºä¾‹:[/bold]")
    console.print("[green]python main.py research --query \"ç›˜ç‚¹ç›®å‰ä¸»æµçš„æœºå™¨å­¦ä¹ æ¡†æ¶\" --template survey[/green]")
    
    console.print("\n[bold]4. å®è·µæŒ‡å—ç¤ºä¾‹:[/bold]")
    console.print("[green]python main.py research --query \"å¦‚ä½•ä½¿ç”¨Kuberneteséƒ¨ç½²åº”ç”¨\" --template tutorial[/green]")
    
    console.print("\n[bold]5. é«˜çº§é€‰é¡¹ç¤ºä¾‹:[/bold]")
    console.print("[green]python main.py research --query \"ä½ çš„æŸ¥è¯¢\" --max-iterations 5 --verbose --output custom_report.md[/green]")


@app.command()
def llm():
    """LLMæä¾›å•†ç®¡ç†"""
    console.print("[bold blue]ğŸ¤– LLMæä¾›å•†ç®¡ç†[/bold blue]")
    
    try:
        from src.llm.llm_factory import LLMFactory
        
        # æ˜¾ç¤ºæ”¯æŒçš„æä¾›å•†
        providers = LLMFactory.get_supported_providers()
        console.print(f"\n[green]æ”¯æŒçš„LLMæä¾›å•†:[/green] {', '.join(providers)}")
        
        # æ˜¾ç¤ºæ¯ä¸ªæä¾›å•†çš„è¯¦ç»†ä¿¡æ¯
        console.print("\n[bold]æä¾›å•†è¯¦ç»†ä¿¡æ¯:[/bold]")
        for provider in providers:
            try:
                info = LLMFactory.get_provider_info(provider)
                console.print(f"\n[cyan]{provider.upper()}:[/cyan]")
                console.print(f"  æè¿°: {info['description']}")
                console.print(f"  å¯ç”¨æ¨¡å‹: {', '.join(info['available_models'][:3])}{'...' if len(info['available_models']) > 3 else ''}")
            except Exception as e:
                console.print(f"[red]âŒ[/red] è·å–{provider}ä¿¡æ¯å¤±è´¥: {str(e)}")
        
        # æ˜¾ç¤ºå½“å‰é…ç½®
        from src.configs.config import Config
        llm_config = Config.get_llm_config()
        console.print(f"\n[bold]å½“å‰LLMé…ç½®:[/bold]")
        console.print(f"æä¾›å•†: {llm_config['provider']}")
        console.print(f"æ¨¡å‹: {llm_config['model']}")
        console.print(f"APIå¯†é’¥: {'å·²é…ç½®' if llm_config['api_key'] else 'æœªé…ç½®'}")
        
    except ImportError as e:
        console.print(f"[red]âŒ[/red] LLMæ¨¡å—å¯¼å…¥å¤±è´¥: {str(e)}")
        console.print("[yellow]ğŸ’¡[/yellow] è¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰LLMä¾èµ–")


@app.command()
def test():
    """è¿è¡Œæµ‹è¯•å¥—ä»¶"""
    console.print("[blue]ğŸ§ª[/blue] å¼€å§‹è¿è¡Œæµ‹è¯•å¥—ä»¶...")
    
    try:
        import subprocess
        import sys
        
        # è¿è¡Œpytest
        result = subprocess.run([
            sys.executable, "-m", "pytest", "tests/", "-v", "--tb=short"
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            console.print("[green]âœ…[/green] æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            console.print(result.stdout)
        else:
            console.print("[red]âŒ[/red] æµ‹è¯•å¤±è´¥")
            console.print(result.stdout)
            console.print(result.stderr)
            
    except Exception as e:
        console.print(f"[red]âŒ[/red] æµ‹è¯•è¿è¡Œå¤±è´¥: {str(e)}")
        console.print("[yellow]ğŸ’¡[/yellow] è¯·ç¡®ä¿å·²å®‰è£…pytest: pip install pytest")


if __name__ == "__main__":
    app()

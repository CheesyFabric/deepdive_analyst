#!/usr/bin/env python3
"""
LLM é…ç½®ç®¡ç†è„šæœ¬
å¸®åŠ©ç”¨æˆ·é…ç½®å’Œç®¡ç†ä¸åŒçš„LLMæä¾›å•†
"""

import os
import sys
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Prompt, Confirm
from rich.table import Table
from rich import print as rprint

console = Console()

def check_env_file():
    """æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    env_file = Path(".env")
    if env_file.exists():
        console.print("[green]âœ…[/green] .env æ–‡ä»¶å·²å­˜åœ¨")
        return True
    else:
        console.print("[yellow]âš ï¸[/yellow] .env æ–‡ä»¶ä¸å­˜åœ¨")
        return False

def create_env_file():
    """åˆ›å»º .env æ–‡ä»¶"""
    env_content = """# DeepDive Analyst ç¯å¢ƒé…ç½®
# è¯·å¡«å…¥çœŸå®çš„ API å¯†é’¥

# LLM æä¾›å•†é…ç½®
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4000
LLM_TIMEOUT=30
LLM_MAX_RETRIES=3

# LLM åŸºç¡€URLé…ç½®ï¼ˆç”¨äºè‡ªå®šä¹‰éƒ¨ç½²ï¼‰
LLM_BASE_URL=

# OpenAI API é…ç½®
OPENAI_API_KEY=your_openai_api_key_here

# Google Gemini API é…ç½®
GEMINI_API_KEY=your_gemini_api_key_here

# é˜¿é‡Œé€šä¹‰åƒé—® API é…ç½®
QWEN_API_KEY=your_qwen_api_key_here

# Anthropic Claude API é…ç½®
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Tavily æœç´¢APIé…ç½®
TAVILY_API_KEY=your_tavily_api_key_here

# LangSmith é…ç½® (å¯é€‰ï¼Œä½†å¼ºçƒˆæ¨è)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=deepdive-analyst
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# æœç´¢é…ç½®
MAX_SEARCH_RESULTS=10
SEARCH_TIMEOUT=30

# æŠ¥å‘Šé…ç½®
DEFAULT_OUTPUT_FILE=report.md
MAX_REPORT_LENGTH=10000
"""
    
    with open(".env", "w", encoding="utf-8") as f:
        f.write(env_content)
    
    console.print("[green]âœ…[/green] .env æ–‡ä»¶å·²åˆ›å»º")

def show_llm_providers():
    """æ˜¾ç¤ºæ”¯æŒçš„LLMæä¾›å•†"""
    console.print("\n[bold blue]ğŸ¤– æ”¯æŒçš„LLMæä¾›å•†[/bold blue]")
    
    providers_info = [
        {
            "æä¾›å•†": "OpenAI",
            "æ¨¡å‹": "GPT-4, GPT-3.5",
            "APIå¯†é’¥": "OPENAI_API_KEY",
            "è·å–åœ°å€": "https://platform.openai.com/api-keys",
            "ç‰¹ç‚¹": "åŠŸèƒ½å¼ºå¤§ï¼Œæ”¯æŒå¤šç§ä»»åŠ¡"
        },
        {
            "æä¾›å•†": "Google Gemini",
            "æ¨¡å‹": "Gemini Pro, Gemini Flash",
            "APIå¯†é’¥": "GEMINI_API_KEY",
            "è·å–åœ°å€": "https://makersuite.google.com/app/apikey",
            "ç‰¹ç‚¹": "Googleå¼€å‘ï¼Œå¤šæ¨¡æ€æ”¯æŒ"
        },
        {
            "æä¾›å•†": "é˜¿é‡Œé€šä¹‰åƒé—®",
            "æ¨¡å‹": "Qwen Turbo, Qwen Max",
            "APIå¯†é’¥": "QWEN_API_KEY",
            "è·å–åœ°å€": "https://dashscope.console.aliyun.com/",
            "ç‰¹ç‚¹": "ä¸­æ–‡ä¼˜åŒ–ï¼Œå›½å†…è®¿é—®å‹å¥½"
        },
        {
            "æä¾›å•†": "Anthropic",
            "æ¨¡å‹": "Claude 3.5 Sonnet",
            "APIå¯†é’¥": "ANTHROPIC_API_KEY",
            "è·å–åœ°å€": "https://console.anthropic.com/",
            "ç‰¹ç‚¹": "å®‰å…¨æ€§é«˜ï¼Œé•¿æ–‡æœ¬å¤„ç†"
        }
    ]
    
    table = Table(title="LLMæä¾›å•†ä¿¡æ¯")
    table.add_column("æä¾›å•†", style="cyan")
    table.add_column("æ¨¡å‹", style="green")
    table.add_column("APIå¯†é’¥ç¯å¢ƒå˜é‡", style="yellow")
    table.add_column("è·å–åœ°å€", style="blue")
    table.add_column("ç‰¹ç‚¹", style="magenta")
    
    for info in providers_info:
        table.add_row(
            info["æä¾›å•†"],
            info["æ¨¡å‹"],
            info["APIå¯†é’¥"],
            info["è·å–åœ°å€"],
            info["ç‰¹ç‚¹"]
        )
    
    console.print(table)

def get_provider_choice():
    """è·å–ç”¨æˆ·é€‰æ‹©çš„æä¾›å•†"""
    console.print("\n[bold blue]é€‰æ‹©LLMæä¾›å•†[/bold blue]")
    
    providers = ["openai", "gemini", "qwen", "anthropic"]
    
    console.print("è¯·é€‰æ‹©è¦é…ç½®çš„LLMæä¾›å•†:")
    for i, provider in enumerate(providers, 1):
        console.print(f"{i}. {provider.upper()}")
    
    while True:
        try:
            choice = int(Prompt.ask("è¯·è¾“å…¥é€‰æ‹© (1-4)", default="1"))
            if 1 <= choice <= 4:
                return providers[choice - 1]
            else:
                console.print("[red]âŒ[/red] è¯·è¾“å…¥1-4ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            console.print("[red]âŒ[/red] è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")

def get_api_key(provider):
    """è·å–APIå¯†é’¥"""
    provider_info = {
        "openai": {
            "name": "OpenAI",
            "url": "https://platform.openai.com/api-keys",
            "env_var": "OPENAI_API_KEY"
        },
        "gemini": {
            "name": "Google Gemini",
            "url": "https://makersuite.google.com/app/apikey",
            "env_var": "GEMINI_API_KEY"
        },
        "qwen": {
            "name": "é˜¿é‡Œé€šä¹‰åƒé—®",
            "url": "https://dashscope.console.aliyun.com/",
            "env_var": "QWEN_API_KEY"
        },
        "anthropic": {
            "name": "Anthropic Claude",
            "url": "https://console.anthropic.com/",
            "env_var": "ANTHROPIC_API_KEY"
        }
    }
    
    info = provider_info[provider]
    
    console.print(f"\n[bold blue]é…ç½® {info['name']} APIå¯†é’¥[/bold blue]")
    console.print(f"è¯·è®¿é—®: {info['url']}")
    console.print("è·å–APIå¯†é’¥åï¼Œè¯·ç²˜è´´åˆ°ä¸‹æ–¹")
    
    api_key = Prompt.ask(f"è¯·è¾“å…¥ {info['name']} APIå¯†é’¥", password=True)
    return api_key, info['env_var']

def get_model_choice(provider):
    """è·å–æ¨¡å‹é€‰æ‹©"""
    models = {
        "openai": ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-3.5-turbo"],
        "gemini": ["gemini/gemini-1.5-pro", "gemini/gemini-1.5-flash", "gemini/gemini-1.0-pro"],
        "qwen": ["qwen-turbo", "qwen-plus", "qwen-max", "qwen2-turbo"],
        "anthropic": ["claude-3-5-sonnet-20241022", "claude-3-5-haiku-20241022"]
    }
    
    available_models = models.get(provider, ["default"])
    
    console.print(f"\n[bold blue]é€‰æ‹© {provider.upper()} æ¨¡å‹[/bold blue]")
    console.print("å¯ç”¨æ¨¡å‹:")
    for i, model in enumerate(available_models, 1):
        console.print(f"{i}. {model}")
    
    while True:
        try:
            choice = int(Prompt.ask("è¯·é€‰æ‹©æ¨¡å‹", default="1"))
            if 1 <= choice <= len(available_models):
                return available_models[choice - 1]
            else:
                console.print(f"[red]âŒ[/red] è¯·è¾“å…¥1-{len(available_models)}ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            console.print("[red]âŒ[/red] è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")

def update_env_file(provider, api_key, env_var, model):
    """æ›´æ–°.envæ–‡ä»¶"""
    env_file = Path(".env")
    if not env_file.exists():
        create_env_file()
    
    # è¯»å–ç°æœ‰å†…å®¹
    with open(".env", "r", encoding="utf-8") as f:
        content = f.read()
    
    # æ›´æ–°é…ç½®
    content = content.replace("LLM_PROVIDER=openai", f"LLM_PROVIDER={provider}")
    content = content.replace("LLM_MODEL=gpt-4o-mini", f"LLM_MODEL={model}")
    content = content.replace(f"{env_var}=your_{provider}_api_key_here", f"{env_var}={api_key}")
    
    # å†™å›æ–‡ä»¶
    with open(".env", "w", encoding="utf-8") as f:
        f.write(content)
    
    console.print("[green]âœ…[/green] .env æ–‡ä»¶å·²æ›´æ–°")

def verify_configuration():
    """éªŒè¯é…ç½®"""
    console.print("\n[bold blue]ğŸ” éªŒè¯é…ç½®[/bold blue]")
    
    try:
        # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
        project_root = Path(__file__).parent.parent
        sys.path.insert(0, str(project_root))
        
        from src.configs.config import Config
        from src.llm.llm_factory import LLMFactory
        
        # æ£€æŸ¥LLMé…ç½®
        llm_config = Config.get_llm_config()
        
        table = Table(title="LLMé…ç½®çŠ¶æ€")
        table.add_column("é…ç½®é¡¹", style="cyan")
        table.add_column("çŠ¶æ€", style="green")
        table.add_column("å€¼", style="yellow")
        
        # æ£€æŸ¥å„ä¸ªé…ç½®é¡¹
        config_items = [
            ("æä¾›å•†", llm_config['provider']),
            ("æ¨¡å‹", llm_config['model']),
            ("æ¸©åº¦", str(llm_config['temperature'])),
            ("æœ€å¤§Tokenæ•°", str(llm_config['max_tokens'])),
            ("APIå¯†é’¥", "å·²é…ç½®" if llm_config['api_key'] else "æœªé…ç½®")
        ]
        
        for item, value in config_items:
            status = "âœ… å·²é…ç½®" if value and value != "æœªé…ç½®" else "âŒ æœªé…ç½®"
            table.add_row(item, status, str(value))
        
        console.print(table)
        
        # éªŒè¯é…ç½®æœ‰æ•ˆæ€§
        if Config.validate_llm_config():
            console.print("[green]âœ…[/green] LLMé…ç½®éªŒè¯æˆåŠŸï¼")
            
            # å°è¯•åˆ›å»ºLLMå®ä¾‹
            try:
                llm_instance = LLMFactory.create_llm(**llm_config)
                console.print(f"[green]âœ…[/green] LLMå®ä¾‹åˆ›å»ºæˆåŠŸ: {llm_instance}")
                return True
            except Exception as e:
                console.print(f"[red]âŒ[/red] LLMå®ä¾‹åˆ›å»ºå¤±è´¥: {str(e)}")
                return False
        else:
            console.print("[red]âŒ[/red] LLMé…ç½®éªŒè¯å¤±è´¥")
            return False
            
    except ImportError as e:
        console.print(f"[red]âŒ[/red] å¯¼å…¥å¤±è´¥: {str(e)}")
        console.print("[yellow]ğŸ’¡[/yellow] è¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–")
        return False

def show_next_steps():
    """æ˜¾ç¤ºåç»­æ­¥éª¤"""
    console.print("\n[bold blue]ğŸš€ åç»­æ­¥éª¤[/bold blue]")
    
    steps = [
        "è¿è¡Œé…ç½®æ£€æŸ¥: python main.py config",
        "æŸ¥çœ‹LLMæä¾›å•†ä¿¡æ¯: python main.py llm",
        "æ‰§è¡Œæµ‹è¯•è°ƒç ”: python main.py research --query 'æµ‹è¯•æŸ¥è¯¢' --verbose",
        "è¿è¡Œå¯è§†åŒ–æ¼”ç¤º: python examples/langsmith_visualization_example.py"
    ]
    
    for i, step in enumerate(steps, 1):
        console.print(f"[green]{i}.[/green] {step}")
    
    console.print("\n[yellow]ğŸ’¡[/yellow] æç¤º: ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨ä¸åŒçš„LLMæä¾›å•†è¿›è¡ŒæŠ€æœ¯è°ƒç ”äº†ï¼")

def main():
    """ä¸»å‡½æ•°"""
    console.print(Panel.fit(
        "[bold blue]LLM é…ç½®ç®¡ç†[/bold blue]\n"
        "ä¸º DeepDive Analyst é¡¹ç›®é…ç½®å¤šLLMæä¾›å•†æ”¯æŒ",
        title="æ¬¢è¿",
        border_style="blue"
    ))
    
    # æ£€æŸ¥ .env æ–‡ä»¶
    if not check_env_file():
        if Confirm.ask("æ˜¯å¦åˆ›å»º .env æ–‡ä»¶ï¼Ÿ"):
            create_env_file()
        else:
            console.print("[red]âŒ[/red] éœ€è¦ .env æ–‡ä»¶æ‰èƒ½ç»§ç»­é…ç½®")
            return
    
    # æ˜¾ç¤ºLLMæä¾›å•†ä¿¡æ¯
    show_llm_providers()
    
    # è·å–ç”¨æˆ·é€‰æ‹©
    if Confirm.ask("æ˜¯å¦ç°åœ¨é…ç½®LLMæä¾›å•†ï¼Ÿ"):
        provider = get_provider_choice()
        api_key, env_var = get_api_key(provider)
        model = get_model_choice(provider)
        
        if api_key:
            update_env_file(provider, api_key, env_var, model)
            console.print("[green]âœ…[/green] LLMé…ç½®å®Œæˆ")
        else:
            console.print("[red]âŒ[/red] æœªæä¾›APIå¯†é’¥")
            return
    else:
        console.print("[yellow]ğŸ’¡[/yellow] æ‚¨å¯ä»¥ç¨åæ‰‹åŠ¨ç¼–è¾‘ .env æ–‡ä»¶æ¥é…ç½®LLM")
        return
    
    # æœ€ç»ˆéªŒè¯
    console.print("\n[bold blue]ğŸ” æœ€ç»ˆéªŒè¯[/bold blue]")
    if verify_configuration():
        show_next_steps()
    else:
        console.print("[red]âŒ[/red] é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")

if __name__ == "__main__":
    main()
